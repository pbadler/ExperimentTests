\documentclass[12pt]{article}

\usepackage{amsmath,amsfonts,amssymb,graphicx,natbib,setspace,authblk} \usepackage{float}
\usepackage[running]{lineno} \usepackage[vmargin=1in,hmargin=1in]{geometry}

\usepackage{enumitem} \setlist{topsep=.125em,itemsep=-0.15em,leftmargin=0.75cm}
\setlength{\parindent}{0.0in} \setlength{\parskip}{0.12in}
\usepackage[compact]{titlesec} 

\usepackage{bm,mathrsfs}
\usepackage{mathptmx} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%% Just for commenting
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\usepackage[usenames]{color}
\definecolor{ForestGreen}{rgb}{0.1,0.44,0.1} 
\definecolor{blue}{rgb}{0,0,0.7} 
\definecolor{red}{rgb}{0.8,0,0}

\newcommand{\new}{\textcolor{red}} 
\newcommand{\comment}{\textcolor{ForestGreen}}
\newcommand{\response}{\textcolor{blue}}

\renewcommand{\floatpagefraction}{0.98} 
\renewcommand{\topfraction}{0.99} 
\renewcommand{\textfraction}{0.05}
\clubpenalty = 10000 \widowpenalty = 10000
\newcommand{\be}{\begin{equation}} 
\newcommand{\ee}{\end{equation}} 
\newcommand{\ba}{\begin{equation} \begin{aligned}} 
\newcommand{\ea}{\end{aligned} \end{equation}}

\def\X{\mathbf{X}} \def\A{\mathbf{A}} \def\B{\mathbf{B}} \def\C{\mathbf{C}} \def\D{\mathbf{D}}
\def\G{\mathbf{G}} \def\H{\mathbf{H}} \def\N{\mathbf{N}} \def\M{\mathbf{M}} \def\W{\mathbf{\Omega}}
\def\P{\mathbf{P}} \def\V{\mathbf{V}} \def\r{r^{\vphantom{0}}} \def\rbar{\bar{r}^{\vphantom{0}}}
\def\E{\mathbb{E}}

\newcommand{\s}[1]{{#1}^{\#}} 
\newcommand{\f}[1]{{#1}^{\flat}} 
\newcommand{\br}[1]{\langle {#1} \rangle}
\newcommand{\bs}{\backslash}

\newcommand{\numcirc}[1] {\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {#1}}}}

\begin{document} 
\centerline{\large{Response to reviews}} 


\normalsize 

Dear Tom,

We really appreciated the quality of the reviews we received. Both reviewers and yourself clearly ``got" the paper -- both its strengths and weaknesses. We have revised the ms. to highlight those strengths and shore up the weaknesses. In particular, we have 1) added text to the Introduction and Discussion to emphasize the importance, generality, and novelty of our work, and 2) added new text and supplementary figures to the Methods to justify the decisions we made in designing our data analysis. In our point-by-point response below, the original reviewer comments are in black and \response{our responses are in blue.} In the manuscript file, we have highlighted new and revised sections with red print. We hope you will find this version of the manuscript suitable for publication.

Thanks for your work,

Peter Adler (on behalf of all coauthors)

Miller's comments: 

Your manuscript has been evaluated by two reviewers with expertise in plant competition and population/community ecology. As you will see, they appreciate the value of confronting model predictions with experiments and your very rigorous approach to this problem. I am in agreement with the reviewers about the strengths of the manuscript, though I also agree that there is some room for improvement in pitch and clarity. Both reviewers noted that the fit for Ecology can be strengthened (and the 'confirmatory' impression can be reduced), particularly in the Discussion, by generalizing beyond your study system and addressing bigger-picture issues about the merits of different approaches to estimating competitive interactions. Reviewer 1 further raised some concerns about your analyses, including clarity of methods and accounting for uncertainty in parameter estimates. Reviewer 2 (see attachment) noted that low cover, especially of grasses, likely contributed to weak competitive effects, and suggests some additional or alternative interpretation of the results. 

My own main concern overlaps with Reviewer 1 regarding the clarity and interpretation of your statistical analysis. The manuscript sends mixed messages about how you estimated the removal treatment coefficient. There are (at least) two ways to do this. You could (A) fit a full model, including a removal coefficient (Eq 1), to all the data and evaluate significance of the removal term. This is suggested by the sentences at lines 171-173 ('note that these are not estimated as separate models'). Or you could (B) fit the crowding coefficients (your $\omega_{jm}$) from the control plots, then use them (as fixed values) in a second round of models fit to the removal plots that include a removal term (as a free parameter) and evaluate the significance of this coefficient. This is suggested at lines 263-268 ('would indicate effect larger or smaller than predicted by a model based on data from control plots'). Reviewer 1 and I have the intuition that method B is a better way to evaluate whether observational data can predict the effects of removals. Under method A (if that is what you did), I do not see why the treatment coefficient would be interpreted as the under- or over-estimation of competition. If the full model is fit to all the data, then the removal coefficient should instead reflect the difference between control and removal plots that is not related to competition, especially if both plot types spanned similar ranges of crowding environments, as you suggest (lines 289-293). This could perhaps be some unintended effect of herbicide or spatial location. In your revision, please take care to improve the communication and justification of your methods for testing whether observational data can predict the effects of experimental removals. 

\response{ This is an insightful comment, and we understand your point. There are two reasons why your suggested approaches A and B will not differ in our case. First, to answer Reviewer 1's question about this same issue, ``including the removal experiment data in model fitting \emph{does not} alter the estimates of (intra- and inter-specific) competition parameters," or any other parameters for that matter. We estimated a version of our P. spicata growth model using only data from control plots. The correlation between the parameters estimated by that model and the parameters estimated by a model fit to all data is 0.99983. Results for P. secunda were similar.  So there is no evidence of interactions between the removal treatment and other parameters in the model. }

\response{Second, to clarify why all the differences between demographic performance in control and removal plots can be captured by one removal coefficient that only alters the overall intercept, we drew a new figure (Appendix C-2). To generate this figure, we fit a version of the growth model for P. spicata that did not include crowding from A. tripartita, but includes all other terms in our full model. We then plotted the residuals from this model against the observed values of A. tripartita crowding, using different colors from points for the control plots and the A. tripartita removal plots. The control plots points stretch out across the x-axis from A. tripartita values of zero up to a maximum of 70, and demonstrate a very weak but negative relationship between A. tripartita crowding and P. spicata growth. The slope of this line is the competition coefficient we estimate. However, all of the points for the removal plots, where A. tripartita cover is zero by design, are stacked on top of each other at x = 0. The figure shows that P. spicata plants experiencing zero A. tripartita crowding are growing faster in removal plots than in control plots, but it also shows why our removals provide no inference about the slope of the fitted line. So you are correct that we cannot clearly distinguish between two potential causes of the positive removal effect, one being that our observational data lead to an underestimate of A. tripartita competitive effects, and the other being that, in your words, ``the difference between control and removal plots...is not related to competition."  In retrospect, rather than only doing complete A. tripartita removals, we should have included partial removals. That said, while we now know how to conduct an even stronger test of our model in the future, the test we did conduct does represent a significant advance beyond the existing state of the art. To clarify these issues, we have added a new paragraph to the Methods section (lines 182-198), along with the new Appendix figure (C-2). We also mention in the Discussion how we would do it differently next time (line 460). }


Other suggestions:

- The abstract can be strengthened all around. It is very narrowly motivated (first words: 'A previous study').

\response{We revised the abstract to broaden the motivation.}

- line 32: add 'of competitors' following 'Stable coexistence'

\response{Done.}

- line 33: use of 'we' here is awkward because it is a different 'we' than at line 61

\response{Fixed.}

- Figure 5: You incorporate random year effects into these cover estimates, so they are basically the stationary distributions of cover. Your vital rate models included spatial random effects. Can you incorporate these too?

\response{We could. In fact, for our short-term population projections, which we compare directly to observed cover values, we do include spatial random effects. However, for these long-term projections, we just wanted to focus on changes in cover for a hypothetical, average plot. If we incorporated the spatial random effects, we would generate six slightly different versions of this plot, but because none of the other parameters vary spatially, the effects of removals on each species would not change much at all. We have added a sentence to the Methods clarifying our choice to exclude spatial variation (line 255). }

- You find that competitive interactions are weak, and that your models do a good job at predicting them. I could imagine that weak interactions make removal effects easy to predict (nothing happens!). You conclude that the success of this case study supports the use of multi-species models built from observational data. Do you think this conclusion will apply to communities with stronger competition? You might address this issue in your Discussion.

\response{We added a new ``lessons learned" paragraph to the Discussion where we address this point (yes, we see no reason why
multispecies models would not also work in communities with stronger competition), along with other generalizations 
from our experience on this project (lines 459-470).  }

Reviewer: 1

Comments to the Author

Adler et al. describes a removal experiment to test competitive release in sagebrush steppe. It is related to a previous survey, which found very little evidence of interspecific competition, predicting that competitive release would be minimal in this system. Results from the experiment largely confirm predictions based on observational models – there are only a few instances where the removal treatment has an impact on survival, growth, or recruitment above and beyond the effects of interspecific competition. And, for 3 of 4 species, these impacts to not scale up to affect population growth rate or equilibrium cover. I really liked this paper! It has important implications for the use of long-term survey data for assessing community dynamics. It is great to see observational models coupled with experiments to test the bounds of what our models can be used to predict. It is a very thorough examination of competitive release, and I think it is the kind of classic ecological topic that would appeal to a large audience. I have a few major and minor comments below.

\response{Thank you for the positive feedback!}

Major comments:

Originally I did not realize that you were fitting one model to the survey and removal experiment simultaneously. I thought that you would want to separate the data used to parameterize the model vs. the data used to test the model.  I wonder how much the removal experiment data is influencing parameters (other than the removal effect) in the model. One constraint of using survey data to fit models is that often natural communities do not experience a wide range of conditions (i.e., grass and Artemisia both at low cover or a rainy year with low crowding). Does including the removal experiment data in model fitting alter the estimates of (intra- and inter-specific) competition parameters because it encompasses combinations of the dependent variables that do not exist in the survey? This may particularly be important for the grass removal plots because they did not go to 0 immediately and thus exhibit variability (such that the model might want to adjust the slope/competition parameter rather than add a removal intercept effect). I think you tried to address this issue with Figure C-3 but I was confused by that graph (see minor comments below), and I think it would be better to either to 1) mathematically argue that the experimental data does not influence parameters other than the removal effect or 2) fit models using only the survey data and show that the parameter estimates are unchanged. 

\response{We addressed this point above, in response to Miller's comments. Briefly, adding data from the removal experiments does not alter estimates of competition coefficients, but rather alters only estimates of model intercepts because crowding from removed species always equals zero. As a result, a separate intercept for removal plots captures the effects of the removals. We have clarified this in a new Methods paragraph and an additional Appendix figure (C-2).}

Possibly related to this – where the removal and competition parameters correlated?

\response{We are not sure what correlation the reviewer is interested in 
(correlations in the MCMC chains?), but perhaps our assurance that
adding the removal data does not alter the competition coefficients 
helps allay the implicit concern.}

Another thing that kept crossing my mind as I read the paper was about the treatment of ``non-significant'' parameters, i.e., parameters with high uncertainty. As far as I could tell throughout the paper, parameters were never dropped from models, and projections were done using the parameter estimates based on the mean of the MCMC chain values. I was struggling with what it means to use parameters with high uncertainty in projections. You explain that you want to use the deterministic versions of the models (line 186) rather than a draw from the Poisson random variable; however those deterministic values of lambda have uncertainty. In your simulations you could incorporate that uncertainty by taking a random draw from the MCMC chain for each parameter (I don't know if this is standard practice). It seemed that this would somehow “equalize” parameter uncertainty (in competition, yearly intercept, removal parameters, etc.). I'm not sure if this would change the conclusions, the only thing it might do is make the variance larger in Fig. 5, and thus the P. spicata Removal model/no ARTR might not look as different from the other P. spicata models. I'm not saying you need to do this, I'm just curious if you had considered this issue at all.

\response{This is a good point, and we appreciate being pushed to justify our decision to ignore parameter uncertainty. Our goal is to test
whether competitive release is as small as our previous model predicted. To be conservative, we want to make it as easy as possible for the model to show 
large effects from removals. That is why we included the ``maximum removal effect'' simulation based on the outer limits of the removal effect
confidence intervals. Propagating parameter uncertainty through our simulations would add noise, making it \emph{harder} to 
detect the effects of removals. More formally, our previous result showed that the interspecific competition coefficients are small in an ecologically
relevant sense: the shift in mean cover due to interspecific competition shown in Fig. 5 is (for 3 species) small compared to the natural fluctuations in cover driven by interannual environmental variability. If, as suggested, we had made those projections with parameter uncertainty on top of the random year effects, 
we would be conflating parameter uncertainty with environmental variability, ``tilting'' the comparison in our favor by overstating the magnitude 
of natural fluctuations. One point of Fig. 5 is that for \emph{P. spicata} the small effect of competition with ARTR each year add 
up (in the model) to a nontrivial long-term effect. We have added a new paragraph to the Methods section ``Individual Based Models" that makes these points (lines 219-231). }

 
My last comment, and really the only negative thing I can say about this paper is that it comes across as rather confirmatory in nature. It is absolutely solid science and 
highly interesting and important but the writing does not punch you with novelty. I think some small changes in wording could highlight that this is quite novel and hasn't 
been assessed in any other systems. 

\response{We all agreed that this is the first time we have been accused of underselling a result! We have added a new paragraph to the Introduction
to highlight the novelty of our approach and to show how it answers a growing chorus of calls for predictive tests (lines 75-81). Also, in the Discussion, we 
added some text to further emphasize why our study is a strong test of a prediction (lines 399-403). }

Minor comments:

Abstract

Can you mention how many species you were modeling somewhere near the beginning of the abstract?

\response{Stated in first sentence of Abstract.}

Lines 19-20: instead of ``population models based on vital rate regressions'' maybe say ``population projections based on vital rate regressions" 
or ``population predictions'' so it does not sound like you are fitting new models. 

\response{Good suggestion, done.}

Line 20: The first time I read this I was not sure what you meant by ``vital rate regressions''. Maybe put this in parenthesis up in lines 7-9?

\response{Done.}

Line 25: while a competition coefficient is often understood to represent resource competition, it can also represent any other 
density dependent effect like microbial effects, right?

\response{Good point, we changed ``resource competition" to ``feedbacks''. }

Introduction

Methods

Lines 137-139:  When did you survey the removal plots? What month and for how many years? 

\response{We added the following sentence, ``We repeated mapped censuses of all plots each June from 2012-2016''.}

Lines 150-173: In this section, I was confused what plots (survey plots or removal experiment) you were using to fit the models. Originally I had thought you would use only the survey plots to fit the models, then hold those parameters constant and add the removal parameter and fit the models to the removal data. I had thought that you would want to separate the data used to parameterize the model vs. the data used to test the model. I then realized that you were fitting the model to all data simultaneously (survey and removal experiment). Maybe be explicit somewhere? 

\response{The new Methods paragraph (lines 182-198) addresses these questions directly.}

Were the 2011 pretreatment data in the removal plots used as the conditions for t=1 in the model (i.e. for the competitive effects)? I don’t think it should be, because for the majority of the 2011-2012 transition, the target species were growing without competition from the removed species. Thus you might find that when there was a lot of Artemisia pretreatment in 2011, there is a large positive growth response in 2012.

\response{We added this sentence to the Methods: ``For plants in removal plots in 2012, we set crowding for removed neighbor species to zero, rather than using the pre-treatment (2011) data.''}

Line 186: what is A-5?

\response{We have clarified that this is an Equation.}

Lines 181-198: if the removal effect is not ``significant'' (credible intervals overlap 0) is it still included in projections?

\response{Yes, we now clarify this in the new Methods paragraph on parameter uncertainty. Note that most of the parameters close
to zero are the interspecific interaction effects. If we set those to zero, or dropped them from the simulations, it would further reduce the 
magnitude of competitive release predicted by the model.}

Results

Line 263:  When I read this I wanted to know something about the uncertainty in these parameters – do most credible intervals overlap zero, or are the coefficients small but ``significant''?

\response{We added this sentence: ``The intraspecific interaction effects are large and have credible intervals that do not overlap zero, while the interspecific coefficients are small and the majority have credible intervals that do overlap zero." }

Lines 277-283: Does the root zone of \emph{Artemisia} generally fall under its canopy? Or is it larger in diameter than the aboveground canopy? Do you think the primary limiting resource is nutrients/moisture or light?

\response{We altered this section to be clear that competition for light or for soil resources should be stronger under the canopy. We also added a caveat in the Discussion (in response to Reviewer 2) about roots extending beyond canopies. }

Line 291: Can you add some explanation to the ``break covariances in plant densities'' part? It took me a while to figure out what you meant. 

\response{We replaced ``break covariances in plant densities among species" with ``result in combinations of neighborhood-scale densities that deviate 
from naturally occurring patterns of correlation.''}

Discussion
Line 421: remove one of the ``dynamics” words 

\response{Thank you, fixed.}

Tables and Figures:

Fig. 1: I’m confused how the focal species account for 70\% basal and 60\% canopy cover (as stated in the methods), but the mean cover values for the grasses in Fig. 1 range from only 1-3\%. I realize your estimates of cover were highly precise, but it seems that it would be hard to model species that are at such low abundance.

\response{We address this point in detail in response to Reviewer 2's comment below.}

Fig. 4. I imagine you omitted error bars from these graphs b/c it might get messy, but I would like to see them (possibly in the supplement). It would be helpful, especially for P. spicata, to assess how off the predictions were, i.e. do error bars overlap?

\response{The requested figure is included below (Fig. 1). It shows broad overlap, but we think it is too messy to include in the supplement. }

 \begin{figure}[tbp]
 \centering
 \includegraphics[width=1\textwidth]{cover_projections_1stepBARS}
 \caption{ Same as Fig. 4 in the main text, but with error bars showing 1 standard deviation of the mean. }
 \label{fig:projectionsBars}
 \end{figure}

Supplementary

Figure C-3: I’m having a hard time interpreting this figure. If you look at the second box from the left on the top row (W.ARTR vs. W.HECO). The y axis is crowding from Artemisia. The red points are plots where Artemisia was removed. Why do the red points range from 0-60 on the y axis? Shouldn't they all be near 0? Or are pretreatment conditions in the removal plots included here? 

\response{We revised the legend to clarify that the red points for Artemisia are pre-treatment values.}

Reviewer: 2

This study investigates whether models parameterized from historical data sets accurately describes
interspecific interactions by assessing whether additional terms are needed to account for removal
results beyond predictions from non-experimental data sets. Previous work led by Adler using models
based on historical data has produced important results, e.g., on the role of the storage effect and of
niche vs neutral processes in community dynamics, so I applaud their attempt to confirm model validity
and strengthen those results. On the other hand, I do have some concerns about the robustness of the
results, as described below. More broadly, even if the conclusions are robust, the manuscript could use
greater efforts to generalize beyond the validity of these particular models for these species. It would
be much appropriate for a general journal such as Ecology if the results were used to draw conclusions
on when modeling approaches will underestimate or overestimate interaction effects. Focusing the
discussion on such questions would be more appropriate than the current discussion material on
coexistence and inter- vs intraspecific competition, which are not part of the research questions that
end the Introduction.

\response{We have added a new Discussion paragraph to directly address these questions about methodological 
generalizations (line 459-470).}

One concern in the design is based on the relatively low covers, especially of the grasses. Based on
Figure 1, basal grass cover per species is very low even before removal—1-2\% per species. Finding
significant effects of such low cover on shrubs would indeed be surprising. Given this low expectation,
this does not seem a very strong test of whether model predictions are valid or not for the shrub. Does
the model even predict any effect of grass removals at these levels? Should the grass removal
treatment even be included in the study? The parameters estimated for A. tripartita seem to be very
uncertain in any case (pp 16-17), further suggesting that the results for this species do not add the story.

\response{We can offer multiple lines of evidence that low grass cover is not the cause of weak grass effects. 
First, grass cover is high enough to cause the strong intraspecific competition that our data analysis detected. 
The puzzle is why interspecific effects of grasses are so much weaker than their intraspecific effects. Second, our growth and survival models do not
depend on average cover but rather neighborhoood scale cover: even if average cover is low, a
grass species may reach high abundance in a particular neighborhood, as seen in the Appendix figures
showing distribution of crowding values, and exert strong per-unit-area effects on another plant. The grasses do in fact
affect Artemisia, as shown in Tables B-2 (marginally significant effect of H. comata on Artemisia survival), B-6 (significant 
effect of Poa on Artemisia growth, and  B-15 (P. spicata has a positive effect on Artemisia recruitment, while H. comata
has a negative effect; the 95\% CIs do not overlap zero). Finally,
grasses are mapped in the currency of basal cover, while for Artemisia canopy cover is mapped. To help readers
appreciate that the observed values of grass basal cover are not trivial, we have added a new supplementary figure (C-1) showing 
photos of example quadrats before and after the removal treatment.  }

The test of the effects of shrubs on grasses is stronger (mean initial shrub cover was ca. 30\% before
removal) and indeed two out of three tests found significant shrub removal effects on growth beyond
the regressions on neighborhood crowding, as well as on population growth and the removal model
provides better predictions from the IBM for P. spicata. However, the authors argued this result may
not reflect stronger interspecific competition than estimated by the model because the release was no
greater for plants originally under a canopy than outside a sagebrush canopy. However, that argument
only makes sense either if competition is only for light or if the canopy edge reflects the edge of the
rooting zone as well. Given the habitat, I doubt the former is true and the authors also suggest it is
unlikely (line 442). For the latter, is anything known about the relationship of root distribution to
canopy cover in A. tripartita? My guess is that roots extend well beyond the canopy edge in these
habitats, leaving underestimated competitive interactions as a likely explanation for the significant
removal effect.

\response{This is a fair point. We added a sentence noting that grasses in interspaces 
could still experience competition if shrub roots extend beyond canopies (line 438).}

Given this result for P. spicata, line 401 of the discussion is a bit surprising: ``how to reconcile the
insensitivity of grasses to sagebrush removal... .'' On the other hand, it does hold for two of the grasses
and some discussion of why the grass species differ in sensitivity to shrub removal would be interesting.
Regardless of which species it holds for, the authors then attempt to reconcile the insensitivity found in
this study with strong effects found in the rangeland ecology literature by noting the relatively low shrub
cover (and small size of A. tripartita) in these ungrazed areas to explain the lack of strong effect of shrub
removal on grasses (lines 401-412). I agree this is a reasonable explanation and would argue that this is
also a possible, even likely, explanation for lack of effect of the grasses on sagebrush as above. In either
case, this reason for weak interspecific interactions (few interspecific neighbors) is quite different from
the ecological explanations in the next paragraph (lines 413-426; e.g., resource partitioning, balance of
facilitation and competition) and has quite different implications from those discussed in the
subsequent paragraph (lines 427-438). If this material stays, it would be helpful to compare and
contrast these different sorts of explanations and their implications more directly.

\response{We thank the reviewer for pointing out this apparent contradiction. In fact, consistent with 
the reviewers' critique of our argument, we actually demonstrated that 
artificially increasing Artemisia cover would not lead to a much bigger competitive release. We have added text to this 
section to suggest that overgrazing must do more than simply increase shrub cover, but must also alter
the per capita competition coefficients, potentially by altering the balance between competition and facilitation
or changing resource availability (lines 455-457). }

A few minor points:

Lines 50-53: Are these two sentences partly saying the same thing? If there is full compensation, the
response must depend on how much was removed, i.e., the degree of dominance.

\response{We revised this passage to make it clear that the second sentence involves partial, not full
compensation.}

Line 81: should ``determine'' be replaced by ``estimate''?

\response{We have added ``estimated" later in the sentence to recognize the uncertainty in the model.}

Line 87: given that you earlier defined competitive release as a population response, should
``competitive release'' at the end of this sentence be replaced by ``individual response to neighbors''?
The second question more directly addresses the population consequences.

\response{We went with ``underestimate the response to decreased crowding'' because our recruitment model does not operate 
at the level of individuals.}

Line 216: ``very similar to those used in our previous studies'' is a bit confusing. Why not just use the
vital rate functions calculated in the first part of the study? If they are indeed the same, say so rather
than introducing similarity to other published studies again.

\response{We do use the vital rate functions calculated in the first part of \emph{this} study, but they differ in very subtle ways 
from the models used in our previous studies. We have revised the sentence to clarify this.}

Line 234-235: Several confusing points here: a) The distinction between the community reaching
equilibrium (500 time steps) and each species reaching equilibrium cover (``additional 2000 time steps'')
is not clear. b) I assume the random year effects were used for all 2500 time steps? c) were the 3
scenarios applied AFTER the community reached equilibrium but before the 2000 steps, i.e., removal
from an equilibrium community? Or from the beginning of each set of runs?

\response{This was bad phrasing on our part, which we have corrected. 
The community equilibrium is not a constant level of cover for each species, as it would be in a deterministic
model, but a steady-state pattern of fluctuations over time. The additional 2000 time steps are needed to compute the average cover of each species
at the community steady-state. We have re-phrased and expanded these sentences to clarify this point. b) Yes, that's right. The paragraph
has been reorganized to clarify this point. c) The scenarios were applied from the very beginning; the paragraph has been re-organized to 
clarify this point.}

Fig. 4. Is the baseline removal line missing for H. comata?

\response{It is there, but virtually indistinguishable from the removal effect line; we've added text to the legend to point this out.}

I found several of the supplemental figures to be somewhat confusing, most notably Figure C-3. This is
potentially important information about the distribution of crowding coefficients between removals and
controls, but I can’t quite figure out what each combination represents.

\response{We have revised the legend of this figure to better explain what it shows.}

\end{document}
