\documentclass[12pt]{article}

\usepackage{amsmath,amsfonts,amssymb,graphicx,natbib,setspace,authblk} \usepackage{float}
\usepackage[running]{lineno} \usepackage[vmargin=1in,hmargin=1in]{geometry}

\usepackage{enumitem} \setlist{topsep=.125em,itemsep=-0.15em,leftmargin=0.75cm}
\setlength{\parindent}{0.0in} \setlength{\parskip}{0.12in}
\usepackage[compact]{titlesec} 

\usepackage{bm,mathrsfs}
\usepackage{mathptmx} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%% Just for commenting
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\usepackage[usenames]{color}
\definecolor{ForestGreen}{rgb}{0.1,0.44,0.1} 
\definecolor{blue}{rgb}{0,0,0.7} 
\definecolor{red}{rgb}{0.8,0,0}

\newcommand{\new}{\textcolor{red}} 
\newcommand{\comment}{\textcolor{ForestGreen}}
\newcommand{\response}{\textcolor{blue}}

\renewcommand{\floatpagefraction}{0.98} 
\renewcommand{\topfraction}{0.99} 
\renewcommand{\textfraction}{0.05}
\clubpenalty = 10000 \widowpenalty = 10000
\newcommand{\be}{\begin{equation}} 
\newcommand{\ee}{\end{equation}} 
\newcommand{\ba}{\begin{equation} \begin{aligned}} 
\newcommand{\ea}{\end{aligned} \end{equation}}

\def\X{\mathbf{X}} \def\A{\mathbf{A}} \def\B{\mathbf{B}} \def\C{\mathbf{C}} \def\D{\mathbf{D}}
\def\G{\mathbf{G}} \def\H{\mathbf{H}} \def\N{\mathbf{N}} \def\M{\mathbf{M}} \def\W{\mathbf{\Omega}}
\def\P{\mathbf{P}} \def\V{\mathbf{V}} \def\r{r^{\vphantom{0}}} \def\rbar{\bar{r}^{\vphantom{0}}}
\def\E{\mathbb{E}}

\newcommand{\s}[1]{{#1}^{\#}} 
\newcommand{\f}[1]{{#1}^{\flat}} 
\newcommand{\br}[1]{\langle {#1} \rangle}
\newcommand{\bs}{\backslash}

\newcommand{\numcirc}[1] {\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {#1}}}}

\begin{document} 
\centerline{\large{Response to reviews}} 


\normalsize 

Dear Tom,

We really appreciated the quality of the reviews we received. Both reviewers and yourself clearly "got" the paper -- both its strengths and weaknesses. We have revised the ms. to highlight those strengths and shore up the weaknesses. In particular, we have 1) added text to the Introduction (and Discussion??) to emphasize the importance and novelty of our work, and 2) added new text and supplementary figures to the Methods to justify the decisions we made in designing our data analysis. In our point-by-point response below, the original reviewer comments are in black and \response{our responses are in blue.} We hope you fill this version of the manuscript suitable for publication.

Thanks for your work,

Peter Adler (on behalf of all coauthors)

Miller's comments: 

Your manuscript has been evaluated by two reviewers with expertise in plant competition and population/community ecology. As you will see, they appreciate the value of confronting model predictions with experiments and your very rigorous approach to this problem. I am in agreement with the reviewers about the strengths of the manuscript, though I also agree that there is some room for improvement in pitch and clarity. Both reviewers noted that the fit for Ecology can be strengthened (and the 'confirmatory' impression can be reduced), particularly in the Discussion, by generalizing beyond your study system and addressing bigger-picture issues about the merits of different approaches to estimating competitive interactions. Reviewer 1 further raised some concerns about your analyses, including clarity of methods and accounting for uncertainty in parameter estimates. Reviewer 2 (see attachment) noted that low cover, especially of grasses, likely contributed to weak competitive effects, and suggests some additional or alternative interpretation of the results. 

My own main concern overlaps with Reviewer 1 regarding the clarity and interpretation of your statistical analysis. The manuscript sends mixed messages about how you estimated the removal treatment coefficient. There are (at least) two ways to do this. You could (A) fit a full model, including a removal coefficient (Eq 1), to all the data and evaluate significance of the removal term. This is suggested by the sentences at lines 171-173 ('note that these are not estimated as separate models'). Or you could (B) fit the crowding coefficients (your $\omega_{jm}$) from the control plots, then use them (as fixed values) in a second round of models fit to the removal plots that include a removal term (as a free parameter) and evaluate the significance of this coefficient. This is suggested at lines 263-268 ('would indicate effect larger or smaller than predicted by a model based on data from control plots'). Reviewer 1 and I have the intuition that method B is a better way to evaluate whether observational data can predict the effects of removals. Under method A (if that is what you did), I do not see why the treatment coefficient would be interpreted as the under- or over-estimation of competition. If the full model is fit to all the data, then the removal coefficient should instead reflect the difference between control and removal plots that is not related to competition, especially if both plot types spanned similar ranges of crowding environments, as you suggest (lines 289-293). This could perhaps be some unintended effect of herbicide or spatial location. In your revision, please take care to improve the communication and justification of your methods for testing whether observational data can predict the effects of experimental removals. 

\response{ This is an insightful comment, and we understand your point. There are two reasons why your suggested approaches A and B will not differ in our case. First, to answer Reviewer 1's question about this same issue, ``including the removal experiment data in model fitting \emph{does not} alter the estimates of (intra- and inter-specific) competition parameters," or any other parameters for that matter. We estimated a version of our P. spicata growth model using only data from control plots (and dropping the removal treatment effect). The correlation between the parameters estimated by that model and the parameters estimated by a model fit to all data is 0.99983. Results for P. secunda were similar.  So there is no evidence of interactions between the removal treatment and other parameters in the model. Second, to clarify why all the differences between demographic performance in control and removal plots can be captured by one removal coefficient that only alters the overall intercept, we drew a new figure (Appendix C-???). To generate this figure, we fit a version of the growth model for P. spicata that did not include crowding from A. tripartita, but includes all other terms in our full model. We then plotted the residuals from this model against the observed values of A. tripartita crowding, using different colors from points for the control plots and the A. tripartita removal plots. The control plots points stretch out across the x-axis from A. tripartita values of zero up to a maximum of 70, and demonstrate a very weak but negative relationship between A. tripartita crowding and P. spicata growth. The slope of this line is the competition coefficient we estimate. However, all of the points for the removal plots, where A. tripartita cover is zero by design, are stacked on top of each other at x = 0. The figure shows that P. spicata plants experiencing zero A. tripartita crowding are growing faster in removal plots than in control plots, but it also shows why our removals provide no inference about the slope of the fitted line. So you are correct that we cannot clearly distinguish between two potential causes of the positive removal effect, one being that our observational data lead to an underestimate of A. tripartita competitive effects, and the other being that, in your words, ``the difference between control and removal plots...is not related to competition."  In retrospect, rather than only doing complete A. tripartita removals, we should have included partial removals. That said, while we now know how to conduct an even stronger test of our model in the future, the test we did conduct does represent a significant advance beyond the existing state of the art.

To clarify these issues, we have added new text to Methods??? Results??? Discussion???, including the figure showing the marginal effects of A. tripartita crowding. Should we also mention how we would do it differently next time, in Discussion???}


Other suggestions:

- The abstract can be strengthened all around. It is very narrowly motivated (first words: 'A previous study').

\response{Steve, want to take a crack at it?}

- line 32: add 'of competitors' following 'Stable coexistence'

\response{Done.}

- line 33: use of 'we' here is awkward because it is a different 'we' than at line 61

\response{Fixed.}

- Figure 5: You incorporate random year effects into these cover estimates, so they are basically the stationary distributions of cover. Your vital rate models included spatial random effects. Can you incorporate these too?

\response{We could. In fact, for our short-term population projections, which we compare directly to observed cover values, we do include spatial random effects. However, for these long-term projections, we just wanted to focus on changes in cover for a hypothetical, average plot. If we incorporated the spatial random effects, we would six slightly different versions of this plot, but because none of the other parameters vary spatially, the effects of removals on each species would not change much at all. We have added a sentence to the methods justifying our choice to exclude spatial variation DO THIS. }

- You find that competitive interactions are weak, and that your models do a good job at predicting them. I could imagine that weak interactions make removal effects easy to predict (nothing happens!). You conclude that the success of this case study supports the use of multi-species models built from observational data. Do you think this conclusion will apply to communities with stronger competition? You might address this issue in your Discussion.

\response{ ??? I don't have any good ideas about what to say. We could mention that a next step is testing predictions about strong INTRAspecific competition...????  }

Reviewer: 1

Comments to the Author

Adler et al. describes a removal experiment to test competitive release in sagebrush steppe. It is related to a previous survey, which found very little evidence of interspecific competition, predicting that competitive release would be minimal in this system. Results from the experiment largely confirm predictions based on observational models – there are only a few instances where the removal treatment has an impact on survival, growth, or recruitment above and beyond the effects of interspecific competition. And, for 3 of 4 species, these impacts to not scale up to affect population growth rate or equilibrium cover. I really liked this paper! It has important implications for the use of long-term survey data for assessing community dynamics. It is great to see observational models coupled with experiments to test the bounds of what our models can be used to predict. It is a very thorough examination of competitive release, and I think it is the kind of classic ecological topic that would appeal to a large audience. I have a few major and minor comments below.

\response{Thank you for the positive feedback!}

Major comments:

Originally I did not realize that you were fitting one model to the survey and removal experiment simultaneously. I thought that you would want to separate the data used to parameterize the model vs. the data used to test the model.  I wonder how much the removal experiment data is influencing parameters (other than the removal effect) in the model. One constraint of using survey data to fit models is that often natural communities do not experience a wide range of conditions (i.e., grass and Artemisia both at low cover or a rainy year with low crowding). Does including the removal experiment data in model fitting alter the estimates of (intra- and inter-specific) competition parameters because it encompasses combinations of the dependent variables that do not exist in the survey? This may particularly be important for the grass removal plots because they did not go to 0 immediately and thus exhibit variability (such that the model might want to adjust the slope/competition parameter rather than add a removal intercept effect). I think you tried to address this issue with Figure C-3 but I was confused by that graph (see minor comments below), and I think it would be better to either to 1) mathematically argue that the experimental data does not influence parameters other than the removal effect or 2) fit models using only the survey data and show that the parameter estimates are unchanged. 

\response{We addressed this point above, in response to Miller's comments. Briefly, adding data from the removal experiments does not alter estimates of competition coefficients, but rather alters estimated of model intercepts because crowding from removed species must equal zero. As a result, a separate intercept for removal plots captures the effects of the removals. We have clarified this in...DO THIS}

\response{Giles commented via email: fitting on one data set and then testing on another will tend to magnify differences and there aren’t valid tests for them. DO WE WANT TO INCLUDE THIS POINT AS WELL? }

Possibly related to this – where the removal and competition parameters correlated?

\response{Not sure what the reviewer means...perhaps correlated in the MCMC chains?}

Another thing that kept crossing my mind as I read the paper was about the treatment of “non-significant” parameters, i.e., parameters with high uncertainty. As far as I could tell throughout the paper, parameters were never dropped from models, and projections were done using the parameter estimates based on the mean of the MCMC chain values. I was struggling with what it means to use parameters with high uncertainty in projections. You explain that you want to use the deterministic versions of the models (line 186) rather than a draw from the Poisson random variable; however those deterministic values of lambda have uncertainty. In your simulations you could incorporate that uncertainty by taking a random draw from the MCMC chain for each parameter (I don't know if this is standard practice). It seemed that this would somehow “equalize” parameter uncertainty (in competition, yearly intercept, removal parameters, etc.). I’m not sure if this would change the conclusions, the only thing it might do is make the variance larger in Fig. 5, and thus the P. spicata Removal model/no ARTR might not look as different from the other P. spicata models. I’m not saying you need to do this, I’m just curious if you had considered this issue at all.

\response{ This is a good point, and we appreciate being pushed to justify our decision to ignore parameter uncertainty. Our goal is to test
whether competitive release is as small as our previous model predicted. To be conservative, we want to make it as easy as possible to
model large effects of removals.  Propagating parameter uncertainty through our simulations would add noise, making it \emph{harder} to 
detect the effects of removals. More formally, our previous result showed that the interspecific competition coefficients are small in an ecologically
relevant sense: the shift in mean cover due to interspecific competition shown in Fig. 5 is (for 3 species) small compared to the natural fluctuations in cover driven by interannual environmental variability. 
If we made the projections with parameter uncertainty (as suggested) on top of random year effects, we would be conflating parameter uncertainty with environmental variability, ``tilting'' the
comparison in our favor by overstating the magnitude of natural fluctuations. One point of Fig. 5 is that for \emph{P. spicata} the small effect of competition with ARTR each year adds up (in the model) to a nontrivial long-term effect.

We have added new text to the Methods to justify our approach...DO THIS...add new paragraph in section: Integral projection models...
  }

 
My last comment, and really the only negative thing I can say about this paper is that it comes across as rather confirmatory in nature. It is absolutely solid science and 
highly interesting and important but the writing does not punch you with novelty. I think some small changes in wording could highlight that this is quite novel and hasn't 
been assessed in any other systems. 

\response{We all agreed that this is the first time we have been accused of underselling a result! We have added a new paragraph to the Introduction
to highlight the novelty of our approach and to show how it answers a growing chorus of calls for more predictive tests. DO THIS...
Also add material to Discussion???}

\response{SPE: here are a few more ideas, or maybe expansions on Peter's ideas and those in the paper. According to \texttt{http://onlinelibrary.wiley.com/doi/10.1111/cobi.12049/abstract}, 
population models fitted to observational data don't do well at out-of-sample prediction, because
conditions change and consequently out-of-sample environments are different from in-sample environments. Here we have a rare, perhaps unique, opportunity to (a) test the out-of-sample 
predictive power of models fitted to observational data when effects of changing environmental conditions are accounted for (in our case, by using the control plots to estimate random year effects), 
and (b) test the specific finding of Adler et al. (2010) that interspecific competition is very weak, relative to intraspecific, in this system. Given the conflicting results 
about the relative importance of within- and between-species competition, as reviewed in the manuscript, 
it is very informative to test the Adler et al. (2010) specific conclusions and thereby test the reliability of conclusions from models fitted to observational
data. Maybe it would also be worth talking about the fact that experimental comparisons of inter- vs intra-specific competition (such as Pantastico-Caldas, M. and D. L. Venable. 1993. 
Competition in two species of desert annuals along a topographic gradient. Ecology 74: 2192-2203) often (typically?) reach the opposite conclusion from observational studies (i.e, experiments
suggest that within- and between-species competition are comparable in strength). Are experimental tests too artificial, not capturing the processes that actually make inter$\gg$intra, or are 
models based on observational data too unreliable? The answer is important for our understanding of how plant communities operate, and for how we should study plant communities in the future.
The more we can say about our results having general methodological conclusions for future work, the more it will do for our ``general significance'' score.} 

Minor comments:

Abstract

Can you mention how many species you were modeling somewhere near the beginning of the abstract?

\response{Stated in first sentence of abstract.}

Lines 19-20: instead of “population models based on vital rate regressions” maybe say “population projections based on vital rate regressions” or “population predictions” so it does not sound like you are fitting new models

\response{Good suggestion, done.}

Line 20: The first time I read this I was not sure what you meant by “vital rate regressions”. Maybe put this in parenthesis up in lines 7-9?

\response{Done.}

Line25: while a competition coefficient is often understood to represent resource competition, it can also represent any other density dependent effect like microbial effects, right?

\response{Good point, we changed ``resource competition" to ``feedbacks."}

Introduction

Methods

Lines 137-139:  When did you survey the removal plots? What month and for how many years? 

Lines 150-173: In this section, I was confused what plots (survey plots or removal experiment) you were using to fit the models. Originally I had thought you would use only the survey plots to fit the models, then hold those parameters constant and add the removal parameter and fit the models to the removal data. I had thought that you would want to separate the data used to parameterize the model vs. the data used to test the model. I then realized that you were fitting the model to all data simultaneously (survey and removal experiment). Maybe be explicit somewhere? 

Were the 2011 pretreatment data in the removal plots used as the conditions for t=1 in the model (i.e. for the competitive effects)? I don’t think it should be, because for the majority of the 2011-2012 transition, the target species were growing without competition from the removed species. Thus you might find that when there was a lot of Artemisia pretreatment in 2011, there is a large positive growth response in 2012.

\response{I zeroed out the removal species for the t=1 data}

Line 186: what is A-5?

\response{We have clarified that this is an Equation.}

Lines 181-198: if the removal effect is not “significant” (credible intervals overlap 0) is it still included in projections?

\response{Yes, this relates to the main concern about propagating uncertainty. ADDRESS THIS IN TEXT}


Results

Line 263:  When I read this I wanted to know something about the uncertainty in these parameters – do most credible intervals overlap zero, or are the coefficients small but “significant”?

Lines 277-283: Does the root zone of Artemisia generally fall under its canopy? Or is it larger in diameter than the aboveground canopy? Do you think the primary limiting resource is nutrients/moisture or light?

Line 291: Can you add some explanation to the “break covariances in plant densities” part? It took me a while to figure out what you meant. 

Discussion
Line 421: remove one of the “dynamics” words 

Tables and Figures:

Fig. 1: I’m confused how the focal species account for 70\% basal and 60\% canopy cover (as stated in the methods), but the mean cover values for the grasses in Fig. 1 range from only 1-3\%. I realize your estimates of cover were highly precise, but it seems that it would be hard to model species that are at such low abundance.

Fig. 4. I imagine you omitted error bars from these graphs b/c it might get messy, but I would like to see them (possibly in the supplement). It would be helpful, especially for P. spicata, to assess how off the predictions were, i.e. do error bars overlap?

\response{UGH}

Supplementary

Figure C-3: I’m having a hard time interpreting this figure. If you look at the second box from the left on the top row (W.ARTR vs. W.HECO). The y axis is crowding from Artemisia. The red points are plots where Artemisia was removed. Why do the red points range from 0-60 on the y axis? Shouldn't they all be near 0? Or are pretreatment conditions in the removal plots included here? 

\response{We revised the legend to clarify that the red points for Artemisia are pre-treatment values.}

Reviewer: 2

This study investigates whether models parameterized from historical data sets accurately describes
interspecific interactions by assessing whether additional terms are needed to account for removal
results beyond predictions from non-experimental data sets. Previous work led by Adler using models
based on historical data has produced important results, e.g., on the role of the storage effect and of
niche vs neutral processes in community dynamics, so I applaud their attempt to confirm model validity
and strengthen those results. On the other hand, I do have some concerns about the robustness of the
results, as described below. More broadly, even if the conclusions are robust, the manuscript could use
greater efforts to generalize beyond the validity of these particular models for these species. It would
be much appropriate for a general journal such as Ecology if the results were used to draw conclusions
on when modeling approaches will underestimate or overestimate interaction effects. Focusing the
discussion on such questions would be more appropriate than the current discussion material on
coexistence and inter- vs intraspecific competition, which are not part of the research questions that
end the Introduction.

\response{Not sure what to say about when models will under/over estimate interaction effects. Thoughts? Avoid extrapolation? Other platitudes?
Or simply say that we need more tests of this kind to answer these questions. }

One concern in the design is based on the relatively low covers, especially of the grasses. Based on
Figure 1, basal grass cover per species is very low even before removal—1-2\% per species. Finding
significant effects of such low cover on shrubs would indeed be surprising. Given this low expectation,
this does not seem a very strong test of whether model predictions are valid or not for the shrub. Does
the model even predict any effect of grass removals at these levels? Should the grass removal
treatment even be included in the study? The parameters estimated for A. tripartita seem to be very
uncertain in any case (pp 16-17), further suggesting that the results for this species do not add the story.

\response{We can offer multiple lines of evidence that low grass cover is not the cause of weak grass effects. 
First, grass cover is high enough to cause strong intraspecific competition. The puzzle is why interspecific effects
of grasses are so weak when their intraspecific effects are strong. Second, our growth and survival models do not
depend on average cover but rather neighborhoood scale cover: even if average cover is low, a
grass species may reach high abundance in a particular neighborhood, as seen in the Appendix figures
showing distribution of crowding values, and exert strong per-unit-area effects on another plant. The grasses do in fact
affect Artemisa, as shown in Tables B-2 (marginally significant effect of H. comata on Artemisia survival), B-6 (significant 
effect of Poa on Artemisia growth, and  B-15 (P. spicata has a positive effect on Artemisia recruitment, while H. comata
has a negative effect; the 95\% CIs do not overlap zero). Finally,
grasses are mapped in the currency of basal cover, while for Artemisia canopy cover is mapped. To help readers
appreciate that small values of basal cover are not trivial, we have added a new supplementary figure showing 
photos of example quadrats before and after the removal treatment. (ADD FIG NUMBER)  }

The test of the effects of shrubs on grasses is stronger (mean initial shrub cover was ca. 30\% before
removal) and indeed two out of three tests found significant shrub removal effects on growth beyond
the regressions on neighborhood crowding, as well as on population growth and the removal model
provides better predictions from the IBM for P. spicata. However, the authors argued this result may
not reflect stronger interspecific competition than estimated by the model because the release was no
greater for plants originally under a canopy than outside a sagebrush canopy. However, that argument
only makes sense either if competition is only for light or if the canopy edge reflects the edge of the
rooting zone as well. Given the habitat, I doubt the former is true and the authors also suggest it is
unlikely (line 442). For the latter, is anything known about the relationship of root distribution to
canopy cover in A. tripartita? My guess is that roots extend well beyond the canopy edge in these
habitats, leaving underestimated competitive interactions as a likely explanation for the significant
removal effect.

\response{TO DO: add caveat}

Given this result for P. spicata, line 401 of the discussion is a bit surprising: “how to reconcile the
insensitivity of grasses to sagebrush removal…..” On the other hand, it does hold for two of the grasses
and some discussion of why the grass species differ in sensitivity to shrub removal would be interesting.
Regardless of which species it holds for, the authors then attempt to reconcile the insensitivity found in
this study with strong effects found in the rangeland ecology literature by noting the relatively low shrub
cover (and small size of A. tripartita) in these ungrazed areas to explain the lack of strong effect of shrub
removal on grasses (lines 401-412). I agree this is a reasonable explanation and would argue that this is
also a possible, even likely, explanation for lack of effect of the grasses on sagebrush as above. In either
case, this reason for weak interspecific interactions (few interspecific neighbors) is quite different from
the ecological explanations in the next paragraph (lines 413-426; e.g., resource partitioning, balance of
facilitation and competition) and has quite different implications from those discussed in the
subsequent paragraph (lines 427-438). If this material stays, it would be helpful to compare and
contrast these different sorts of explanations and their implications more directly.

\response{We thank the reviewer for pointing out this apparent contradiction. TO DO: ??? reviewer is right
that we seem to be using two different arguments in different places...I need to think about this more...}

A few minor points:

Lines 50-53: Are these two sentences partly saying the same thing? If there is full compensation, the
response must depend on how much was removed, i.e., the degree of dominance.

Line 81: should “determine” be replaced by “estimate”?

Line 87: given that you earlier defined competitive release as a population response, should
“competitive release” at the end of this sentence be replaced by “individual response to neighbors”?
The second question more directly addresses the population consequences.

Line 216: “very similar to those used in our previous studies” is a bit confusing. Why not just use the
vital rate functions calculated in the first part of the study? If they are indeed the same, say so rather
than introducing similarity to other published studies again.

Line 234-235: Several confusing points here: a) The distinction between the community reaching
equilibrium (500 time steps) and each species reaching equilibrium cover (“additional 2000 time steps”)
is not clear. b) I assume the random year effects were used for all 2500 time steps? c) were the 3
scenarios applied AFTER the community reached equilibrium but before the 2000 steps, i.e., removal
from an equilibrium community? Or from the beginning of each set of runs?

\response{ This was bad phrasing on our part. 
The community equilibrium is not a constant level of cover for each species, as it would be in a deterministic
model, but a steady-state pattern of fluctuations over time. The additional 2000 time steps are needed to compute the average cover of each species
at the community steady-state. We have re-phrased and expanded these sentences to clarify this point. b) Yes, that's right. The paragraph
has been reorganized to clarify this point. c) The scenarios were applied from the very beginning; the paragraph has been re-organized to 
clarify this point.}

Fig. 4. Is the baseline removal line missing for H. comata?

I found several of the supplemental figures to be somewhat confusing, most notably Figure C-3. This is
potentially important information about the distribution of crowding coefficients between removals and
controls, but I can’t quite figure out what each combination represents.

\response{We have revised the legend of this figure to better explain what it shows.}

\end{document}
